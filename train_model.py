"""
–ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç Data Leakage

WHY: –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
–±–µ–∑ —Ä–∏—Å–∫–∞ "–∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ".
"""
import asyncio
from repository import PostgresRepository
from datetime import datetime
import os

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DB_DSN = os.getenv('DATABASE_URL', 'postgresql://postgres:password@localhost:5432/trading_db')


async def train_model_example():
    """
    –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è XGBoost –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã.
    
    –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç close —Å–ª–µ–¥—É—é—â–µ–π 1H —Å–≤–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - –¢–µ–∫—É—â–µ–π —Å–≤–µ—á–∏ (OHLCV)
    - –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (OBI, OFI)
    - CVD —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (whale/dolphin/minnow)
    - –î–µ—Ä–∏–≤–∞—Ç–∏–≤–æ–≤ (basis, skew)
    - Smart Money –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (1w/1m/3m/6m trends)
    """
    # 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    repo = PostgresRepository(dsn=DB_DSN)
    await repo.connect()
    
    print("=" * 70)
    print("ü§ñ ML MODEL TRAINING - Data Leakage Protected")
    print("=" * 70)
    
    try:
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —É—Ç–µ—á–µ–∫
        df = await repo.prepare_ml_dataset_safe(
            start_date=datetime(2024, 1, 1),
            end_date=datetime(2024, 12, 1),
            timeframe='1h',
            target_col='next_hour_close',
            symbol='BTCUSDT'
        )
        
        print(f"\nüìä Dataset Summary:")
        print(f"   Rows: {len(df)}")
        print(f"   Columns: {len(df.columns)}")
        print(f"   Date range: {df['candle_time'].min()} ‚Üí {df['candle_time'].max()}")
        print(f"   Target: {df['next_hour_close'].describe()}\n")
        
        # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
        # –£–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        drop_cols = [
            'candle_time', 
            'next_hour_close',  # –¢–∞—Ä–≥–µ—Ç
            'snapshot_time',    # –í—Ä–µ–º—è —Ñ–∏—á–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            'lifecycle_event_id',  # ID (–µ—Å–ª–∏ –µ—Å—Ç—å)
            'symbol',
            'timeframe',
            'aggregation_version'
        ]
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
        drop_cols_existing = [col for col in drop_cols if col in df.columns]
        
        X = df.drop(columns=drop_cols_existing)
        y = df['next_hour_close']
        
        print(f"üéØ Features: {len(X.columns)} columns")
        print(f"   {list(X.columns[:10])}... (showing first 10)\n")
        
        # 4. Train/Test split (–ø–æ –≤—Ä–µ–º–µ–Ω–∏!)
        # IMPORTANT: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º random split –¥–ª—è time-series!
        split_idx = int(len(df) * 0.8)
        
        X_train = X.iloc[:split_idx]
        X_test = X.iloc[split_idx:]
        y_train = y.iloc[:split_idx]
        y_test = y.iloc[split_idx:]
        
        print(f"üìà Train/Test Split:")
        print(f"   Train: {len(X_train)} rows ({len(X_train)/len(df)*100:.1f}%)")
        print(f"   Test: {len(X_test)} rows ({len(X_test)/len(df)*100:.1f}%)\n")
        
        # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        print(f"ü§ñ Training XGBoost model...")
        
        from xgboost import XGBRegressor
        
        model = XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X_train, y_train)
        
        # 6. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        from sklearn.metrics import mean_squared_error, r2_score
        import numpy as np
        
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
        r2_train = r2_score(y_train, y_pred_train)
        r2_test = r2_score(y_test, y_pred_test)
        
        print(f"\n‚úÖ Model Training Complete!")
        print(f"\nüìä Model Performance:")
        print(f"   Train RMSE: {rmse_train:.2f}")
        print(f"   Test RMSE: {rmse_test:.2f}")
        print(f"   Train R¬≤: {r2_train:.4f}")
        print(f"   Test R¬≤: {r2_test:.4f}")
        
        # 7. Feature Importance (—Ç–æ–ø-10)
        import pandas as pd
        
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nüéØ Top 10 Most Important Features:")
        for idx, row in feature_importance.head(10).iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")
        
        print(f"\n" + "=" * 70)
        print(f"‚úÖ SUCCESS - Model trained without data leakage!")
        print(f"=" * 70)
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # 8. –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        await repo.close()


if __name__ == '__main__':
    asyncio.run(train_model_example())
