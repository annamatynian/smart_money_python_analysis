"""
üõ°Ô∏è ML Data Quality Guards - –ó–∞—â–∏—Ç–∞ –æ—Ç Data Leakage

WHY: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç "–∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏–µ –≤ –±—É–¥—É—â–µ–µ" –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ ML –º–æ–¥–µ–ª–µ–π.
–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è time-series –¥–∞–Ω–Ω—ã—Ö (SmartCandles + IcebergFeatures).

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥ model.fit() –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞.
"""
import pandas as pd
import numpy as np
from datetime import timedelta
from colorama import Fore, Style, init
from typing import Optional

init(autoreset=True)


class DataLeakageGuard:
    """
    üõ°Ô∏è GUARDIAN OF TIME
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ 5 —Ç–∏–ø–æ–≤ —É—Ç–µ—á–µ–∫ –ø–µ—Ä–µ–¥ ML-–æ–±—É—á–µ–Ω–∏–µ–º:
    1. Timestamp Alignment - —Ñ–∏—á–∏ –Ω–µ –∏–∑ –±—É–¥—É—â–µ–≥–æ
    2. Correlation Spike - —Ç–∞—Ä–≥–µ—Ç –Ω–µ –ø–æ–¥–º–µ—à–∞–Ω –∫–∞–∫ —Ñ–∏—á–∞
    3. Shift Integrity - lag-—Ñ–∏—á–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–¥–≤–∏–Ω—É—Ç—ã
    4. Timeframe Mixing - 1H —Å–≤–µ—á–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç 4H –∫–æ–Ω—Ç–µ–∫—Å—Ç
    5. Aggregation Version - –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ '1.0'
    
    Usage:
        guard = DataLeakageGuard(df, time_col='candle_time', target_col='next_hour_close')
        guard.check_all()  # –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏, –ø–∞–¥–∞–µ—Ç —Å ValueError –ø—Ä–∏ —É—Ç–µ—á–∫–µ
    """

    def __init__(self, df: pd.DataFrame, time_col: str, target_col: str):
        """
        Args:
            df: –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (SmartCandles + Features merged)
            time_col: –ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–≤–µ—á–∏ (candle_time)
            target_col: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, next_hour_close)
        """
        self.df = df.sort_values(by=time_col).reset_index(drop=True)
        self.time_col = time_col
        self.target_col = target_col
        self.issues_found = []

    # =========================================================================
    # –ü–†–û–í–ï–†–ö–ê 1: TIMESTAMP ALIGNMENT (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è)
    # =========================================================================
    def check_timestamp_alignment(self, feature_time_col: str):
        """
        –ü–†–û–í–ï–†–ö–ê 1: –§–∏–∑–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏.
        –í—Ä–µ–º—è —Ä–∞—Å—á–µ—Ç–∞ —Ñ–∏—á–∏ (snapshot_time) –ù–ï –ú–û–ñ–ï–¢ –±—ã—Ç—å –ø–æ–∑–∂–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫—Ä—ã—Ç–∏—è —Å–≤–µ—á–∏ (candle_time).
        
        –ü—Ä–∏–º–µ—Ä —É—Ç–µ—á–∫–∏:
        - –°–≤–µ—á–∞ Open: 14:00
        - Context Calculated: 14:59
        - –ú–æ–¥–µ–ª—å –≤ 14:00 –ù–ï –ú–û–ñ–ï–¢ –∑–Ω–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ 14:59!
        
        Args:
            feature_time_col: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ —Ñ–∏—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'snapshot_time')
        
        Raises:
            ValueError: –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ feature_time > candle_time
        """
        print(f"{Fore.CYAN}üîç [CHECK 1/5] Timestamp Alignment: {feature_time_col}...{Style.RESET_ALL}")
        
        if feature_time_col not in self.df.columns:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Column '{feature_time_col}' not found. Skipping.{Style.RESET_ALL}")
            return
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –≤—Ä–µ–º—è —Ñ–∏—á–∏ > –≤—Ä–µ–º–µ–Ω–∏ —Å–≤–µ—á–∏ (–£–¢–ï–ß–ö–ê!)
        leaks = self.df[self.df[feature_time_col] > self.df[self.time_col]]
        
        if not leaks.empty:
            example = leaks.iloc[0]
            msg = (
                f"{Fore.RED}üö® CRITICAL LEAK DETECTED!{Style.RESET_ALL}\n"
                f"   Future data found in {len(leaks)}/{len(self.df)} rows ({len(leaks)/len(self.df)*100:.1f}%)\n"
                f"   Example:\n"
                f"     Candle Time: {example[self.time_col]}\n"
                f"     Feature Time: {example[feature_time_col]}\n"
                f"   ‚Üí Feature is {(example[feature_time_col] - example[self.time_col]).total_seconds()} seconds ahead!"
            )
            print(msg)
            self.issues_found.append(f"Timestamp leakage in {feature_time_col}: {len(leaks)} rows")
            raise ValueError(f"Data Leakage: {feature_time_col} contains future timestamps")
        else:
            print(f"{Fore.GREEN}   ‚úÖ OK - No future timestamps detected{Style.RESET_ALL}")

    # =========================================================================
    # –ü–†–û–í–ï–†–ö–ê 2: CORRELATION SPIKE (–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è)
    # =========================================================================
    def check_target_correlation_spike(self, threshold: float = 0.95):
        """
        –ü–†–û–í–ï–†–ö–ê 2: "–°–ª–∏—à–∫–æ–º —Ö–æ—Ä–æ—à–æ, —á—Ç–æ–±—ã –±—ã—Ç—å –ø—Ä–∞–≤–¥–æ–π".
        
        –ï—Å–ª–∏ –∫–∞–∫–∞—è-—Ç–æ —Ñ–∏—á–∞ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ç–∞—Ä–≥–µ—Ç–æ–º > 95%, —ç—Ç–æ –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ —É—Ç–µ—á–∫–∞.
        –ü—Ä–∏–º–µ—Ä: –≤—ã —Å–ª—É—á–∞–π–Ω–æ –ø–æ–¥–∞–ª–∏ close_price –≤ —Ñ–∏—á–∏, –ø—ã—Ç–∞—è—Å—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å close_price.
        
        Args:
            threshold: –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.95 = 95%)
        """
        print(f"{Fore.CYAN}üîç [CHECK 2/5] Correlation Spike (threshold={threshold})...{Style.RESET_ALL}")
        
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∞–º—É —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        exclude = [self.target_col, self.time_col]
        numeric_cols = [col for col in numeric_cols if col not in exclude]
        
        if self.target_col not in self.df.columns:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Target column '{self.target_col}' not found. Skipping.{Style.RESET_ALL}")
            return
        
        correlations = self.df[numeric_cols].corrwith(self.df[self.target_col]).abs()
        suspicious = correlations[correlations > threshold]
        
        if not suspicious.empty:
            msg = f"{Fore.YELLOW}‚ö†Ô∏è  WARNING: Suspiciously high correlations found:{Style.RESET_ALL}"
            print(msg)
            for col, val in suspicious.items():
                print(f"     ‚Ä¢ {col}: {val:.4f}")
                self.issues_found.append(f"High correlation: {col} ({val:.4f})")
            print(f"{Fore.YELLOW}   ‚Üí Check if these are derived directly from the target!{Style.RESET_ALL}")
        else:
            print(f"{Fore.GREEN}   ‚úÖ OK - No suspicious correlations{Style.RESET_ALL}")

    # =========================================================================
    # –ü–†–û–í–ï–†–ö–ê 3: SHIFT INTEGRITY (–£–ª—É—á—à–µ–Ω–Ω–∞—è)
    # =========================================================================
    def check_shift_integrity(self, lag_columns: Optional[list] = None):
        """
        –ü–†–û–í–ï–†–ö–ê 3: Lag-—Ñ–∏—á–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–¥–≤–∏–Ω—É—Ç—ã.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ '_1h_ago', '_prev', '_lag1' –∏ —Ç.–¥.
        —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–¥–≤–∏–Ω—É—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫.
        
        Args:
            lag_columns: –°–ø–∏—Å–æ–∫ lag-–∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–∞–≤—Ç–æ–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –µ—Å–ª–∏ None)
        """
        print(f"{Fore.CYAN}üîç [CHECK 3/5] Shift Integrity (lag features)...{Style.RESET_ALL}")
        
        # –ê–≤—Ç–æ–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ lag-–∫–æ–ª–æ–Ω–æ–∫
        if lag_columns is None:
            suffixes = ['_1h_ago', '_4h_ago', '_1d_ago', '_prev', '_lag1', '_lag']
            lag_columns = [col for col in self.df.columns if any(suf in col for suf in suffixes)]
        
        if not lag_columns:
            print(f"{Fore.YELLOW}   ‚ÑπÔ∏è  No lag columns detected. Skipping.{Style.RESET_ALL}")
            return
        
        print(f"   Found {len(lag_columns)} lag columns to check...")
        
        for lag_col in lag_columns:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
            original_col = None
            for suffix in ['_1h_ago', '_4h_ago', '_1d_ago', '_prev', '_lag1', '_lag']:
                if suffix in lag_col:
                    original_col = lag_col.replace(suffix, '')
                    break
            
            if original_col and original_col in self.df.columns:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º NaN –≤ –Ω–∞—á–∞–ª–µ (–ø—Ä–∏ shift(1) –¥–æ–ª–∂–Ω—ã –ø–æ—è–≤–ª—è—Ç—å—Å—è)
                first_value = self.df[lag_col].iloc[0]
                if pd.notna(first_value):
                    warning = f"   ‚ö†Ô∏è  {lag_col}: No NaN at start (missing shift?)"
                    print(f"{Fore.YELLOW}{warning}{Style.RESET_ALL}")
                    self.issues_found.append(f"Missing shift: {lag_col}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ lag_col[i] ‚âà original_col[i-1]
                expected_shift = self.df[original_col].shift(1)
                actual_lag = self.df[lag_col]
                
                # –î–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –¥–ª—è float
                mismatch = (expected_shift - actual_lag).abs() > 0.0001
                mismatch_count = mismatch.sum()
                
                # –í—ã—á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (—Ç–∞–º –≤—Å–µ–≥–¥–∞ NaN)
                total_comparable = len(self.df) - 1
                mismatch_rate = mismatch_count / total_comparable if total_comparable > 0 else 0
                
                if mismatch_rate > 0.01:  # –ë–æ–ª—å—à–µ 1% –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                    warning = f"   ‚ùå {lag_col}: {mismatch_count}/{total_comparable} mismatches ({mismatch_rate*100:.1f}%)"
                    print(f"{Fore.RED}{warning}{Style.RESET_ALL}")
                    self.issues_found.append(f"Shift mismatch: {lag_col}")
                else:
                    print(f"{Fore.GREEN}   ‚úÖ {lag_col}: Correct shift{Style.RESET_ALL}")
        
        if not self.issues_found:
            print(f"{Fore.GREEN}   ‚úÖ OK - All lag columns properly shifted{Style.RESET_ALL}")

    # =========================================================================
    # –ü–†–û–í–ï–†–ö–ê 4: TIMEFRAME CONSISTENCY (–°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–ª—è SmartCandles)
    # =========================================================================
    def check_timeframe_consistency(self, timeframe_col: str = 'timeframe'):
        """
        –ü–†–û–í–ï–†–ö–ê 4: –°–º–µ—à–∏–≤–∞–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.
        
        1H —Å–≤–µ—á–∞ –ù–ï –ú–û–ñ–ï–¢ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ 4H/1D —Å–≤–µ—á–∏.
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤ –æ–¥–Ω–æ–º timestamp –Ω–µ —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã.
        
        Args:
            timeframe_col: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'timeframe')
        """
        print(f"{Fore.CYAN}üîç [CHECK 4/5] Timeframe Consistency...{Style.RESET_ALL}")
        
        if timeframe_col not in self.df.columns:
            print(f"{Fore.YELLOW}   ‚ÑπÔ∏è  Column '{timeframe_col}' not found. Skipping.{Style.RESET_ALL}")
            return
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–≤–µ—á–∏ –∏ —Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        grouped = self.df.groupby(self.time_col)[timeframe_col].apply(lambda x: list(set(x)))
        mixed = grouped[grouped.apply(len) > 1]
        
        if not mixed.empty:
            msg = (
                f"{Fore.RED}‚ùå ERROR: Timeframe mixing detected!{Style.RESET_ALL}\n"
                f"   Found {len(mixed)} timestamps with multiple timeframes:\n"
            )
            print(msg)
            for timestamp, frames in mixed.head(3).items():
                print(f"     {timestamp}: {frames}")
            
            self.issues_found.append(f"Timeframe mixing: {len(mixed)} timestamps")
            raise ValueError(f"Timeframe mixing detected in {len(mixed)} timestamps")
        else:
            print(f"{Fore.GREEN}   ‚úÖ OK - No timeframe mixing{Style.RESET_ALL}")

    # =========================================================================
    # –ü–†–û–í–ï–†–ö–ê 5: AGGREGATION VERSION (–°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–ª—è SmartCandles)
    # =========================================================================
    def check_aggregation_version(self, version_col: str = 'aggregation_version', expected_version: str = '1.0'):
        """
        –ü–†–û–í–ï–†–ö–ê 5: –í–µ—Ä—Å–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ SmartCandles.
        
        –í—Å–µ —Å–≤–µ—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–Ω–æ–π –≤–µ—Ä—Å–∏–∏ ('1.0').
        –°–º–µ—à–∏–≤–∞–Ω–∏–µ –≤–µ—Ä—Å–∏–π '0.9' –∏ '1.0' –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º —Ñ–∏—á–∞–º.
        
        Args:
            version_col: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤–µ—Ä—Å–∏–∏
            expected_version: –û–∂–∏–¥–∞–µ–º–∞—è –≤–µ—Ä—Å–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é '1.0')
        """
        print(f"{Fore.CYAN}üîç [CHECK 5/5] Aggregation Version (expected: {expected_version})...{Style.RESET_ALL}")
        
        if version_col not in self.df.columns:
            print(f"{Fore.YELLOW}   ‚ÑπÔ∏è  Column '{version_col}' not found. Skipping.{Style.RESET_ALL}")
            return
        
        versions = self.df[version_col].unique()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –°–º–µ—à–∏–≤–∞–Ω–∏–µ –≤–µ—Ä—Å–∏–π
        if len(versions) > 1:
            msg = (
                f"{Fore.RED}‚ùå ERROR: Mixed aggregation versions!{Style.RESET_ALL}\n"
                f"   Found versions: {versions}\n"
                f"   ‚Üí Do not mix old and new SmartCandles!"
            )
            print(msg)
            self.issues_found.append(f"Mixed versions: {versions}")
            raise ValueError(f"Mixed aggregation versions: {versions}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        if versions[0] != expected_version:
            msg = (
                f"{Fore.YELLOW}‚ö†Ô∏è  WARNING: Using old aggregation version!{Style.RESET_ALL}\n"
                f"   Current: {versions[0]}, Expected: {expected_version}\n"
                f"   ‚Üí Consider regenerating SmartCandles"
            )
            print(msg)
            self.issues_found.append(f"Old version: {versions[0]}")
        else:
            print(f"{Fore.GREEN}   ‚úÖ OK - All data is version {expected_version}{Style.RESET_ALL}")

    # =========================================================================
    # –ó–ê–ü–£–°–ö –í–°–ï–• –ü–†–û–í–ï–†–û–ö
    # =========================================================================
    def check_all(self, feature_time_col: str = 'snapshot_time', 
                  timeframe_col: str = 'timeframe',
                  version_col: str = 'aggregation_version'):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ 5 –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ–¥—Ä—è–¥.
        
        Args:
            feature_time_col: –ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —Ñ–∏—á–∏ (–¥–ª—è check 1)
            timeframe_col: –ö–æ–ª–æ–Ω–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (–¥–ª—è check 4)
            version_col: –ö–æ–ª–æ–Ω–∫–∞ –≤–µ—Ä—Å–∏–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–¥–ª—è check 5)
        
        Raises:
            ValueError: –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —É—Ç–µ—á–∫–∞
        """
        print(f"\n{Fore.MAGENTA}{'='*70}")
        print(f"üõ°Ô∏è  DATA LEAKAGE GUARD - FULL AUDIT")
        print(f"{'='*70}{Style.RESET_ALL}")
        print(f"Dataset: {len(self.df)} rows, {len(self.df.columns)} columns")
        print(f"Time range: {self.df[self.time_col].min()} ‚Üí {self.df[self.time_col].max()}\n")
        
        self.issues_found = []
        
        # 1. Timestamp alignment (–∫—Ä–∏—Ç–∏—á–Ω–∞—è)
        self.check_timestamp_alignment(feature_time_col)
        
        # 2. Correlation spike (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è)
        self.check_target_correlation_spike()
        
        # 3. Shift integrity (lag-—Ñ–∏—á–∏)
        self.check_shift_integrity()
        
        # 4. Timeframe consistency (SmartCandles)
        self.check_timeframe_consistency(timeframe_col)
        
        # 5. Aggregation version (SmartCandles)
        self.check_aggregation_version(version_col)
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        print(f"\n{Fore.MAGENTA}{'='*70}")
        if not self.issues_found:
            print(f"{Fore.GREEN}‚úÖ AUDIT PASSED - Dataset is clean!{Style.RESET_ALL}")
            print(f"{Fore.GREEN}   Safe to proceed with model.fit(){Style.RESET_ALL}")
        else:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  AUDIT COMPLETED WITH WARNINGS:{Style.RESET_ALL}")
            for issue in self.issues_found:
                print(f"   ‚Ä¢ {issue}")
            print(f"\n{Fore.YELLOW}   Review warnings before training.{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}{'='*70}{Style.RESET_ALL}\n")


# =============================================================================
# HELPER: SAFE MERGE –¥–ª—è SmartCandles + Features
# =============================================================================
def safe_merge_candles_features(candles_df: pd.DataFrame, 
                                features_df: pd.DataFrame,
                                candle_time_col: str = 'candle_time',
                                feature_time_col: str = 'snapshot_time') -> pd.DataFrame:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ SmartCandles + IcebergFeatures —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —É—Ç–µ—á–µ–∫.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pd.merge_asof —Å direction='backward', —á—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç:
    - –î–ª—è –∫–∞–∂–¥–æ–π —Å–≤–µ—á–∏ –±–µ—Ä–µ—Ç—Å—è –ë–õ–ò–ñ–ê–ô–®–ò–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ü–†–û–®–õ–û–ì–û
    - –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±—É–¥—É—â–µ–≥–æ –ù–ï–í–û–ó–ú–û–ñ–ï–ù
    
    Args:
        candles_df: SmartCandles (—Ç–∞—Ä–≥–µ—Ç)
        features_df: IcebergFeatures (–ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã)
        candle_time_col: –ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å–≤–µ—á–∞—Ö
        feature_time_col: –ö–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ñ–∏—á–∞—Ö
    
    Returns:
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (—Å–≤–µ—á–∏ + —Ñ–∏—á–∏)
    
    Example:
        candles = await repo.fetch_smart_candles(start, end)
        features = await repo.fetch_feature_snapshots(start, end)
        
        df = safe_merge_candles_features(candles, features)
        # –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—É—á–∞—Ç—å model.fit(df)
    """
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è merge_asof
    candles_sorted = candles_df.sort_values(candle_time_col).reset_index(drop=True)
    features_sorted = features_df.sort_values(feature_time_col).reset_index(drop=True)
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π merge (–±–µ—Ä–µ—Ç —Ç–æ–ª—å–∫–æ backward context)
    merged = pd.merge_asof(
        candles_sorted,
        features_sorted,
        left_on=candle_time_col,
        right_on=feature_time_col,
        direction='backward',  # ‚Üê –ö–õ–Æ–ß–ï–í–ê–Ø –ó–ê–©–ò–¢–ê!
        suffixes=('_candle', '_feature')
    )
    
    print(f"{Fore.CYAN}üîó Safe merge completed:{Style.RESET_ALL}")
    print(f"   Candles: {len(candles_df)} rows")
    print(f"   Features: {len(features_df)} rows")
    print(f"   Merged: {len(merged)} rows")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–≤–µ—á–µ–π –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ —Ñ–∏—á–∏ (NaN –≤ feature_time_col)
    missing_features = merged[feature_time_col].isna().sum()
    if missing_features > 0:
        print(f"{Fore.YELLOW}   ‚ö†Ô∏è  {missing_features} candles have no features (too early){Style.RESET_ALL}")
    
    return merged
