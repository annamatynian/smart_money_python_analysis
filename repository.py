import asyncpg
from decimal import Decimal
from typing import Dict, Optional, List
from datetime import datetime, timedelta
import os
import pandas as pd

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ SmartCandle Ð´Ð»Ñ Ñ‚Ð¸Ð¿Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
from domain_smartcandle import SmartCandle

# ML Data Quality Guards
from utils_ml import DataLeakageGuard, safe_merge_candles_features

class PostgresRepository:
    def __init__(self, dsn: str):
        self.dsn = dsn
        self.pool: Optional[asyncpg.Pool] = None

    async def connect(self):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¿ÑƒÐ» ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð¸ Ð’Ð¡Ð• Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹"""
        self.pool = await asyncpg.create_pool(self.dsn)
        
        async with self.pool.acquire() as conn:
            # 1. Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð ÐÐ™Ð¡Ð‘Ð•Ð Ð“ÐžÐ’ (Iceberg Registry)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS iceberg_levels (
                    price NUMERIC PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    is_ask BOOLEAN NOT NULL,
                    total_hidden_volume NUMERIC NOT NULL,
                    creation_time TIMESTAMPTZ DEFAULT NOW(),
                    last_update_time TIMESTAMPTZ DEFAULT NOW(),
                    status TEXT NOT NULL,
                    is_gamma_wall BOOLEAN DEFAULT FALSE,
                    confidence_score DOUBLE PRECISION,
                    spoofing_probability DOUBLE PRECISION,
                    refill_count INTEGER
                );
            """)

            # 2. Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢Ð ÐžÐ¢ÐœÐ•ÐÐ« (FIX: Ð­Ñ‚Ð¾Ð³Ð¾ Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ð² Ñ‚Ð²Ð¾ÐµÐ¼ ÐºÐ¾Ð´Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ!)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS iceberg_cancellation_context (
                    price NUMERIC PRIMARY KEY,
                    mid_price_at_cancel NUMERIC,
                    distance_from_level_pct NUMERIC,
                    price_velocity_5s NUMERIC,
                    moving_towards_level BOOLEAN,
                    volume_executed_pct NUMERIC,
                    cancelled_at TIMESTAMPTZ DEFAULT NOW()
                );
            """)

            # 3. Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð Ð”Ð›Ð¯ ML ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð¯ (Raw Events)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS iceberg_training_data (
                    id SERIAL PRIMARY KEY,
                    event_time TIMESTAMPTZ,
                    symbol TEXT,
                    price NUMERIC,
                    is_ask BOOLEAN,
                    trade_quantity NUMERIC,
                    visible_volume_before NUMERIC,
                    added_volume NUMERIC,
                    total_accumulated NUMERIC,
                    spread NUMERIC,
                    obi_value NUMERIC,
                    dist_call NUMERIC,
                    dist_put NUMERIC,
                    total_gex NUMERIC,
                    confidence DOUBLE PRECISION,
                    is_breach BOOLEAN DEFAULT FALSE,
                    is_near_gamma_wall BOOLEAN DEFAULT FALSE,
                    gamma_wall_type TEXT
                );
            """)
            
            # 4. Ð¡Ð£ÐŸÐ•Ð -Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð ÐœÐ•Ð¢Ð Ð˜Ðš (Unified Market Metrics)
            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ ÑÑ‚Ð°Ñ€ÑƒÑŽ market_metrics Ð¸ Ð½Ð¾Ð²Ñ‹Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð»Ñ SmartCandle
            # WHY: Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ñ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸ÐµÐ¹ 005 (flow_/wall_/book_ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÑ‹)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS market_metrics_full (
                    time TIMESTAMPTZ NOT NULL,
                    symbol TEXT NOT NULL,
                    price NUMERIC,            -- mid_price
                    spread_bps NUMERIC,
                    
                    -- ÐœÐ¸ÐºÑ€Ð¾ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° (book_ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ = Ð²Ð¸Ð´Ð¸Ð¼Ð°Ñ ÐºÐ½Ð¸Ð³Ð° Ð¾Ñ€Ð´ÐµÑ€Ð¾Ð²)
                    book_ofi NUMERIC,                   -- Order Flow Imbalance
                    book_obi NUMERIC,                   -- Weighted Order Book Imbalance
                    
                    -- ÐÐ³Ñ€ÐµÑÑÐ¾Ñ€Ñ‹ (flow_ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ = Ñ‚Ðµ ÐºÑ‚Ð¾ Ð‘Ð¬ÐÐ¢)
                    flow_whale_cvd_delta NUMERIC,       -- ÐšÐ¸Ñ‚Ñ‹ (>$100k trades)
                    flow_dolphin_cvd_delta NUMERIC,     -- Ð”ÐµÐ»ÑŒÑ„Ð¸Ð½Ñ‹ ($1k-$100k trades)
                    flow_minnow_cvd_delta NUMERIC,      -- Ð Ñ‹Ð±Ñ‹ (<$1k trades)
                    
                    -- Ð¡Ñ‚ÐµÐ½Ñ‹ (wall_ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ = Ð¿Ð°ÑÑÐ¸Ð²Ð½Ñ‹Ðµ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð¸)
                    wall_whale_vol NUMERIC,             -- Whale iceberg volume detected
                    wall_dolphin_vol NUMERIC,           -- Dolphin iceberg volume
                    
                    -- Ð”ÐµÑ€Ð¸Ð²Ð°Ñ‚Ð¸Ð²Ñ‹ (Ð´Ð»Ñ SmartCandle)
                    basis_apr NUMERIC,        -- Ð¤ÑŒÑŽÑ‡ÐµÑ€ÑÐ½Ñ‹Ð¹ Ð±Ð°Ð·Ð¸Ñ
                    options_skew NUMERIC,     -- ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ ÑÑ‚Ñ€Ð°Ñ…
                    oi_delta NUMERIC,         -- Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ OI
                    
                    -- Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð¾Ð»Ñ
                    is_aggressor_buy BOOLEAN
                );
                
                -- Ð˜Ð½Ð´ÐµÐºÑ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ RAG-Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
                CREATE INDEX IF NOT EXISTS idx_metrics_time_symbol 
                ON market_metrics_full (time DESC, symbol);
            """)
            
            # 5. Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð Ð–Ð˜Ð—ÐÐ•ÐÐÐžÐ“Ðž Ð¦Ð˜ÐšÐ›Ð ÐÐ™Ð¡Ð‘Ð•Ð Ð“ÐžÐ’ (Ð´Ð»Ñ ML)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS iceberg_lifecycle (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    symbol TEXT NOT NULL,
                    price NUMERIC NOT NULL,
                    is_ask BOOLEAN NOT NULL,
                    event_type TEXT NOT NULL,  -- 'DETECTED' | 'REFILLED' | 'BREACHED' | 'EXHAUSTED' | 'CANCELLED'
                    event_time TIMESTAMPTZ DEFAULT NOW(),
                    survival_seconds INTEGER,   -- Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾Ð¶Ð¸Ð»
                    total_volume_absorbed NUMERIC,  -- Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¾Ð±ÑŠÐµÐ¼Ð° ÑÑŠÐµÐ»
                    refill_count INTEGER,       -- ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¹
                    outcome TEXT,               -- 'BREACH' | 'EXHAUSTION' | 'CANCEL'
                    price_at_death NUMERIC,     -- Ð¦ÐµÐ½Ð° Ð² Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ ÑÐ¼ÐµÑ€Ñ‚Ð¸
                    price_move_1h_after NUMERIC -- % Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ñ†ÐµÐ½Ñ‹ Ñ‡ÐµÑ€ÐµÐ· 1Ñ‡
                );
                
                CREATE INDEX IF NOT EXISTS idx_lifecycle_symbol_time
                ON iceberg_lifecycle (symbol, event_time DESC);
            """)
            
            # 6. Ð¢ÐÐ‘Ð›Ð˜Ð¦Ð Ð¡ÐÐ˜ÐœÐšÐžÐ’ ÐœÐ•Ð¢Ð Ð˜Ðš (Feature Snapshots)
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS iceberg_feature_snapshot (
                    id SERIAL PRIMARY KEY,
                    lifecycle_event_id UUID NOT NULL,
                    snapshot_time TIMESTAMPTZ NOT NULL,
                    
                    -- Orderbook metrics
                    obi_value DOUBLE PRECISION,
                    ofi_value DOUBLE PRECISION,
                    spread_bps DOUBLE PRECISION,
                    depth_ratio DOUBLE PRECISION,
                    
                    -- Flow metrics (CVD)
                    whale_cvd DOUBLE PRECISION,
                    fish_cvd DOUBLE PRECISION,
                    dolphin_cvd DOUBLE PRECISION,
                    whale_cvd_delta_5m DOUBLE PRECISION,
                    total_cvd DOUBLE PRECISION,
                    
                    -- Derivatives metrics
                    futures_basis_apr DOUBLE PRECISION,
                    basis_state TEXT,
                    options_skew DOUBLE PRECISION,
                    skew_state TEXT,
                    total_gex DOUBLE PRECISION,
                    dist_to_gamma_wall DOUBLE PRECISION,
                    gamma_wall_type TEXT,
                    
                    -- Price metrics
                    current_price DOUBLE PRECISION,
                    twap_5m DOUBLE PRECISION,
                    price_vs_twap_pct DOUBLE PRECISION,
                    volatility_1h DOUBLE PRECISION,
                    
                    -- Spoofing metrics
                    spoofing_score DOUBLE PRECISION,
                    cancel_ratio_5m DOUBLE PRECISION,
                    
                    -- Market regime
                    trend_regime TEXT,
                    volatility_regime TEXT,
                    
                    FOREIGN KEY (lifecycle_event_id) REFERENCES iceberg_lifecycle(id)
                );
                
                CREATE INDEX IF NOT EXISTS idx_feature_lifecycle
                ON iceberg_feature_snapshot (lifecycle_event_id);
            """)
            
            # === SAFE CHANGE: ADD SWING COLUMNS ===
            # WHY: Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð´Ð»Ñ Grim Reaper Ð¸ Smart Money (ÐµÑÐ»Ð¸ Ð¸Ñ… Ð½ÐµÑ‚)
            await conn.execute("""
                ALTER TABLE iceberg_lifecycle 
                ADD COLUMN IF NOT EXISTS intention_type TEXT,       -- 'SCALPER' | 'INTRADAY' | 'POSITIONAL'
                ADD COLUMN IF NOT EXISTS iir_value NUMERIC,         -- Iceberg Impact Ratio
                
                ADD COLUMN IF NOT EXISTS volatility_at_entry NUMERIC, -- ATR Ð² Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð²Ñ…Ð¾Ð´Ð°
                ADD COLUMN IF NOT EXISTS vpin_at_entry NUMERIC,       -- VPIN Ð² Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð²Ñ…Ð¾Ð´Ð°
                ADD COLUMN IF NOT EXISTS t_settled TIMESTAMPTZ,       -- Ð’Ñ€ÐµÐ¼Ñ ÑÑ‚Ð°Ñ€Ñ‚Ð° Ð¿Ð¾ÑÐ»Ðµ Ð¾ÑÑ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ
                
                ADD COLUMN IF NOT EXISTS y_intraday_result INTEGER,   -- 4H-24H Target
                ADD COLUMN IF NOT EXISTS y_swing_result INTEGER,      -- 1D-3D Target
                ADD COLUMN IF NOT EXISTS y_strategic_result INTEGER,  -- 3D-7D Target (MAIN)
                
                ADD COLUMN IF NOT EXISTS y_mfe_mae_ratio NUMERIC,     -- Quality metric
                ADD COLUMN IF NOT EXISTS y_sharpe_ratio NUMERIC;      -- Sharpe metric
            """)
            
            # === SAFE CHANGE: ADD FEATURE COLUMNS (SMART MONEY CONTEXT) ===
            # WHY: Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
            await conn.execute("""
                ALTER TABLE iceberg_feature_snapshot 
                ADD COLUMN IF NOT EXISTS whale_cvd_trend_1w DOUBLE PRECISION,
                ADD COLUMN IF NOT EXISTS whale_cvd_trend_1m DOUBLE PRECISION,
                ADD COLUMN IF NOT EXISTS whale_cvd_trend_3m DOUBLE PRECISION,  -- ÐšÐ’ÐÐ Ð¢ÐÐ›
                ADD COLUMN IF NOT EXISTS whale_cvd_trend_6m DOUBLE PRECISION,
                
                ADD COLUMN IF NOT EXISTS vpin_score DOUBLE PRECISION,
                ADD COLUMN IF NOT EXISTS vpin_level TEXT,
                
                ADD COLUMN IF NOT EXISTS is_htf_divergence INTEGER,
                ADD COLUMN IF NOT EXISTS basis_regime_weekly TEXT;
            """)
            
            print("ðŸ˜ PostgreSQL connected. All tables & Swing columns ready.")

    async def run_migrations(self):
        """
        WHY: ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ SQL Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ migrations/
        
        Ð›Ð¾Ð³Ð¸ÐºÐ°:
        1. Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ _migrations Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¹
        2. Ð¡ÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð°Ð¿ÐºÑƒ migrations/
        3. ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¸ (Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°)
        
        Ð’ÐÐ–ÐÐž: Ð’Ñ‹Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ ÐŸÐžÐ¡Ð›Ð• connect(), Ð½Ð¾ Ð”Ðž Ð½Ð°Ñ‡Ð°Ð»Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð‘Ð”
        """
        if not self.pool:
            raise RuntimeError("Pool not connected. Call connect() first.")
        
        migrations_dir = os.path.join(os.path.dirname(__file__), 'migrations')
        
        if not os.path.exists(migrations_dir):
            print("âš ï¸ No migrations/ directory found. Skipping.")
            return
        
        async with self.pool.acquire() as conn:
            # 1. Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¹
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS _migrations (
                    filename TEXT PRIMARY KEY,
                    applied_at TIMESTAMPTZ DEFAULT NOW()
                );
            """)
            
            # 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº ÑƒÐ¶Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¹
            applied = await conn.fetch("SELECT filename FROM _migrations")
            applied_set = {row['filename'] for row in applied}
            
            # 3. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¹
            migration_files = sorted([
                f for f in os.listdir(migrations_dir) 
                if f.endswith('.sql')
            ])
            
            # 4. ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ð¸
            for filename in migration_files:
                if filename in applied_set:
                    print(f"âœ… Migration {filename} already applied. Skipping.")
                    continue
                
                filepath = os.path.join(migrations_dir, filename)
                
                try:
                    # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ SQL Ñ„Ð°Ð¹Ð»
                    with open(filepath, 'r', encoding='utf-8') as f:
                        sql = f.read()
                    
                    # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸ÑŽ (Ð² Ñ‚Ñ€Ð°Ð½Ð·Ð°ÐºÑ†Ð¸Ð¸)
                    async with conn.transaction():
                        await conn.execute(sql)
                        
                        # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð² _migrations
                        await conn.execute(
                            "INSERT INTO _migrations (filename) VALUES ($1)",
                            filename
                        )
                    
                    print(f"ðŸš€ Migration {filename} applied successfully.")
                    
                except Exception as e:
                    print(f"âŒ Migration {filename} FAILED: {e}")
                    print(f"   Rolling back and stopping migration process.")
                    raise  # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÐµÑÐ»Ð¸ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ñ ÑÐ»Ð¾Ð¼Ð°Ð»Ð°ÑÑŒ
            
            print("âœ¨ All migrations completed.")

    async def close(self):
        if self.pool:
            await self.pool.close()

    # --- ÐœÐ•Ð¢ÐžÐ”Ð« Ð¡ÐžÐ¥Ð ÐÐÐ•ÐÐ˜Ð¯ (WRITERS) ---

    async def save_level(self, level, symbol: str):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ (Iceberg Registry)"""
        if not self.pool: return

        query = """
            INSERT INTO iceberg_levels (
                price, symbol, is_ask, total_hidden_volume, 
                creation_time, last_update_time, status, 
                is_gamma_wall, confidence_score,
                spoofing_probability, refill_count
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
            ON CONFLICT (price) DO UPDATE SET
                total_hidden_volume = EXCLUDED.total_hidden_volume,
                last_update_time = EXCLUDED.last_update_time,
                status = EXCLUDED.status,
                is_gamma_wall = EXCLUDED.is_gamma_wall,
                confidence_score = EXCLUDED.confidence_score,
                spoofing_probability = EXCLUDED.spoofing_probability,
                refill_count = EXCLUDED.refill_count;
        """
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(query, 
                    level.price, symbol, level.is_ask, 
                    level.total_hidden_volume, level.creation_time,
                    level.last_update_time, level.status.value, 
                    level.is_gamma_wall, level.confidence_score,
                    level.spoofing_probability, level.refill_count
                )
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð¼ÐµÐ½Ñ‹, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
                if level.cancellation_context is not None:
                    await self._save_cancellation_context(conn, level)
        except Exception as e:
            print(f"âŒ DB Error (save_level): {e}")

    async def _save_cancellation_context(self, conn, level):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð°Ð½Ñ‚Ð¸-ÑÐ¿ÑƒÑ„Ð¸Ð½Ð³Ð°"""
        ctx = level.cancellation_context
        query = """
            INSERT INTO iceberg_cancellation_context (
                price, mid_price_at_cancel, distance_from_level_pct,
                price_velocity_5s, moving_towards_level, volume_executed_pct
            ) VALUES ($1, $2, $3, $4, $5, $6)
            ON CONFLICT (price) DO UPDATE SET
                mid_price_at_cancel = EXCLUDED.mid_price_at_cancel,
                distance_from_level_pct = EXCLUDED.distance_from_level_pct,
                price_velocity_5s = EXCLUDED.price_velocity_5s,
                moving_towards_level = EXCLUDED.moving_towards_level,
                volume_executed_pct = EXCLUDED.volume_executed_pct,
                cancelled_at = NOW();
        """
        try:
            await conn.execute(query,
                level.price, ctx.mid_price_at_cancel,
                ctx.distance_from_level_pct, ctx.price_velocity_5s,
                ctx.moving_towards_level, ctx.volume_executed_pct
            )
        except Exception as e:
            print(f"âš ï¸ Failed to save cancellation context: {e}")

    async def log_training_event(self, data: dict):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÑ‹Ñ€Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ ML"""
        if not self.pool: return
        
        query = """
            INSERT INTO iceberg_training_data (
                event_time, symbol, price, is_ask,
                trade_quantity, visible_volume_before, 
                added_volume, total_accumulated, 
                spread, obi_value, 
                dist_call, dist_put, total_gex,
                confidence, is_breach,
                is_near_gamma_wall, gamma_wall_type
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
        """
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(query, 
                    data['event_time'], data['symbol'], data['price'], data['is_ask'],
                    data['trade_quantity'], data['visible_volume_before'],
                    data['added_volume'], data['total_accumulated'], 
                    data['spread'], data['obi_value'],
                    data['dist_call'], data['dist_put'], data['total_gex'],
                    data['confidence'], data['is_breach'],
                    data.get('is_near_gamma_wall', False),
                    data.get('gamma_wall_type', None)
                )
        except Exception as e:
            print(f"âŒ ML Logging Error: {e}")

    async def log_full_metric(self, data: dict):
        """
        === GEMINI FIX: ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ð¿Ð¾Ð´ Migration 005 (Flow/Wall Semantics) ===
        
        WHY: ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ñ‹:
        - ofi/obi â†’ book_ofi/book_obi (Ð¾Ñ€Ð´ÐµÑ€Ð±ÑƒÐº Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸)
        - whale_cvd_delta â†’ flow_whale_cvd_delta (Ð°Ð³Ñ€ÐµÑÑÐ¾Ñ€Ñ‹)
        - minnow_cvd_delta â†’ flow_minnow_cvd_delta
        - Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹: flow_dolphin_cvd_delta, wall_whale_vol, wall_dolphin_vol
        """
        if not self.pool: return
        
        query = """
            INSERT INTO market_metrics_full (
                time, symbol, price, spread_bps, 
                book_ofi, book_obi,
                flow_whale_cvd_delta,
                flow_dolphin_cvd_delta,
                flow_minnow_cvd_delta,
                wall_whale_vol,
                wall_dolphin_vol,
                basis_apr, options_skew, oi_delta
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
        """
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(query, 
                    data['timestamp'], 
                    data['symbol'], 
                    data['price'],
                    data.get('spread_bps', 0),
                    data.get('book_ofi', 0),  # âœ… NEW NAME
                    data.get('book_obi', 0),  # âœ… NEW NAME
                    data.get('flow_whale_cvd_delta', 0),  # âœ… NEW NAME
                    data.get('flow_dolphin_cvd_delta', 0),  # âœ… NEW COLUMN
                    data.get('flow_minnow_cvd_delta', 0),  # âœ… NEW NAME
                    data.get('wall_whale_vol', 0),  # âœ… NEW COLUMN
                    data.get('wall_dolphin_vol', 0),  # âœ… NEW COLUMN
                    data.get('basis'), 
                    data.get('skew'), 
                    data.get('oi_delta')
                )
        except Exception as e:
            print(f"âŒ Full Metric Logging Error: {e}")

    # --- ÐœÐ•Ð¢ÐžÐ”Ð« Ð§Ð¢Ð•ÐÐ˜Ð¯ (READERS) ---

    async def load_active_levels(self, symbol: str) -> Dict[Decimal, any]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÑƒÑ€Ð¾Ð²Ð½Ð¸ Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ"""
        if not self.pool: return {}
        loaded_data = {}
        try:
            async with self.pool.acquire() as conn:
                rows = await conn.fetch("""
                    SELECT * FROM iceberg_levels 
                    WHERE symbol = $1 AND status = 'ACTIVE'
                """, symbol)
                for r in rows:
                    price = r['price']
                    loaded_data[price] = dict(r)
            print(f"ðŸ˜ Loaded {len(loaded_data)} levels.")
            return loaded_data
        except Exception as e:
            print(f"âŒ DB Load Error: {e}")
            return {}

    async def get_aggregated_smart_candles(
        self, 
        symbol: str, 
        start_time: datetime, 
        end_time: datetime, 
        timeframe_minutes: int = 60
    ) -> List[SmartCandle]:
        """
        Ð”Ð›Ð¯ ÐÐ“Ð•ÐÐ¢Ð: ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² SmartCandles.
        Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ RAG (Retrieval Augmented Generation).
        """
        if not self.pool: return []

        query = f"""
            SELECT
                to_timestamp(floor((extract('epoch' from time) / {timeframe_minutes * 60})) * {timeframe_minutes * 60}) AT TIME ZONE 'UTC' as candle_time,
                (array_agg(price ORDER BY time ASC))[1] as open,
                MAX(price) as high,
                MIN(price) as low,
                (array_agg(price ORDER BY time DESC))[1] as close,
                COUNT(*) as volume_proxy,
                
                SUM(flow_whale_cvd_delta) as whale_cvd,
                SUM(flow_minnow_cvd_delta) as minnow_cvd,
                SUM(book_ofi) as ofi,
                AVG(book_obi) as weighted_obi,
                AVG(basis_apr) as avg_basis_apr,
                AVG(options_skew) as options_skew,
                SUM(oi_delta) as oi_delta

            FROM market_metrics_full
            WHERE symbol = $1 
              AND time >= $2 
              AND time <= $3
            GROUP BY 1
            ORDER BY 1 ASC;
        """

        smart_candles = []
        try:
            async with self.pool.acquire() as conn:
                rows = await conn.fetch(query, symbol, start_time, end_time)
                for r in rows:
                    candle = SmartCandle(
                        symbol=symbol,
                        timeframe=f"{timeframe_minutes}m",
                        timestamp=r['candle_time'],
                        open=r['open'] or 0, 
                        high=r['high'] or 0, 
                        low=r['low'] or 0, 
                        close=r['close'] or 0,
                        volume=r['volume_proxy'], 
                        
                        whale_cvd=float(r['whale_cvd'] or 0),
                        minnow_cvd=float(r['minnow_cvd'] or 0),
                        total_trades=int(r['volume_proxy']),
                        
                        avg_basis_apr=float(r['avg_basis_apr']) if r['avg_basis_apr'] else None,
                        options_skew=float(r['options_skew']) if r['options_skew'] else None,
                        oi_delta=float(r['oi_delta']) if r['oi_delta'] else None,
                        
                        ofi=float(r['ofi'] or 0),
                        weighted_obi=float(r['weighted_obi'] or 0)
                    )
                    smart_candles.append(candle)
        except Exception as e:
            print(f"âŒ Aggregation Error: {e}")
            
        return smart_candles
    
    # ========================================================================
    # LIFECYCLE & FEATURE SNAPSHOT METHODS (Ð´Ð»Ñ ML)
    # ========================================================================
    
    async def save_lifecycle_event(
        self,
        symbol: str,
        price: Decimal,
        is_ask: bool,
        event_type: str,
        survival_seconds: Optional[int] = None,
        total_volume_absorbed: Optional[Decimal] = None,
        refill_count: Optional[int] = None,
        outcome: Optional[str] = None,
        price_at_death: Optional[Decimal] = None,
        intention_type: Optional[str] = None,  # NEW: 'SCALPER' | 'INTRADAY' | 'POSITIONAL'
        iir_value: Optional[float] = None       # NEW: Iceberg Impact Ratio
    ) -> Optional[str]:
        """
        WHY: Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð¶Ð¸Ð·Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ†Ð¸ÐºÐ»Ð° Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð°.
        
        Args:
            symbol: Ð¡Ð¸Ð¼Ð²Ð¾Ð» (BTCUSDT)
            price: Ð¦ÐµÐ½Ð° Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð°
            is_ask: True ÐµÑÐ»Ð¸ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸
            event_type: 'DETECTED' | 'REFILLED' | 'BREACHED' | 'EXHAUSTED' | 'CANCELLED'
            survival_seconds: Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾Ð¶Ð¸Ð» (Ð·Ð°Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð¿Ñ€Ð¸ ÑÐ¼ÐµÑ€Ñ‚Ð¸)
            total_volume_absorbed: Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¾Ð±ÑŠÐµÐ¼Ð° ÑÑŠÐµÐ»
            refill_count: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¹
            outcome: 'BREACH' | 'EXHAUSTION' | 'CANCEL' | None
            price_at_death: Ð¦ÐµÐ½Ð° Ð² Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ ÑÐ¼ÐµÑ€Ñ‚Ð¸
            intention_type: 'SCALPER' | 'INTRADAY' | 'POSITIONAL' (Smart Money classification)
            iir_value: Iceberg Impact Ratio (hidden_volume / book_depth)
        
        Returns:
            UUID ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð¸Ð»Ð¸ None Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
        """
        if not self.pool:
            return None
        
        query = """
            INSERT INTO iceberg_lifecycle (
                symbol, price, is_ask, event_type, event_time,
                survival_seconds, total_volume_absorbed, refill_count,
                outcome, price_at_death,
                intention_type, iir_value
            ) VALUES ($1, $2, $3, $4, NOW(), $5, $6, $7, $8, $9, $10, $11)
            RETURNING id;
        """
        
        try:
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow(
                    query,
                    symbol, price, is_ask, event_type,
                    survival_seconds, total_volume_absorbed, refill_count,
                    outcome, price_at_death,
                    intention_type, iir_value  # NEW: Smart Money classification
                )
                return str(row['id']) if row else None
        except Exception as e:
            print(f"âŒ Save lifecycle event error: {e}")
            return None
    
    async def save_feature_snapshot(
        self,
        lifecycle_event_id: str,
        snapshot  # FeatureSnapshot object
    ) -> bool:
        """
        WHY: Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ½Ð¸Ð¼Ð¾Ðº Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ñ ML.
        
        Args:
            lifecycle_event_id: UUID ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð¸Ð· iceberg_lifecycle
            snapshot: FeatureSnapshot object Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
        
        Returns:
            True ÐµÑÐ»Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾
        """
        if not self.pool:
            return False
        
        query = """
            INSERT INTO iceberg_feature_snapshot (
                lifecycle_event_id, snapshot_time,
                -- Orderbook
                obi_value, ofi_value, spread_bps, depth_ratio,
                -- Flow
                whale_cvd, fish_cvd, dolphin_cvd, whale_cvd_delta_5m, total_cvd,
                -- Derivatives
                futures_basis_apr, basis_state, options_skew, skew_state,
                total_gex, dist_to_gamma_wall, gamma_wall_type,
                -- Price
                current_price, twap_5m, price_vs_twap_pct, volatility_1h,
                -- Spoofing
                spoofing_score, cancel_ratio_5m,
                -- Regime
                trend_regime, volatility_regime,
                -- Smart Money Context (Step 2)
                whale_cvd_trend_1w, whale_cvd_trend_1m, whale_cvd_trend_3m, whale_cvd_trend_6m,
                vpin_score, vpin_level,
                is_htf_divergence, basis_regime_weekly
            ) VALUES (
                $1, $2,
                $3, $4, $5, $6,
                $7, $8, $9, $10, $11,
                $12, $13, $14, $15,
                $16, $17, $18,
                $19, $20, $21, $22,
                $23, $24,
                $25, $26,
                $27, $28, $29, $30,
                $31, $32,
                $33, $34
            );
        """
        
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(
                    query,
                    lifecycle_event_id, snapshot.snapshot_time,
                    # Orderbook
                    snapshot.obi_value, snapshot.ofi_value, snapshot.spread_bps, snapshot.depth_ratio,
                    # Flow
                    snapshot.whale_cvd, snapshot.fish_cvd, snapshot.dolphin_cvd,
                    snapshot.whale_cvd_delta_5m, snapshot.total_cvd,
                    # Derivatives
                    snapshot.futures_basis_apr, snapshot.basis_state,
                    snapshot.options_skew, snapshot.skew_state,
                    snapshot.total_gex, snapshot.dist_to_gamma_wall, snapshot.gamma_wall_type,
                    # Price
                    snapshot.current_price, snapshot.twap_5m,
                    snapshot.price_vs_twap_pct, snapshot.volatility_1h,
                    # Spoofing
                    snapshot.spoofing_score, snapshot.cancel_ratio_5m,
                    # Regime
                    snapshot.trend_regime, snapshot.volatility_regime,
                    # Smart Money Context (Step 2)
                    snapshot.whale_cvd_trend_1w, snapshot.whale_cvd_trend_1m,
                    snapshot.whale_cvd_trend_3m, snapshot.whale_cvd_trend_6m,  # ÐšÐ’ÐÐ Ð¢ÐÐ›
                    snapshot.vpin_score, snapshot.vpin_level,
                    snapshot.is_htf_divergence, snapshot.basis_regime_weekly
                )
                return True
        except Exception as e:
            print(f"âŒ Save feature snapshot error: {e}")
            return False
    
    async def update_lifecycle_outcome(
        self,
        lifecycle_id: str,
        outcome: str,
        price_move_1h_after: Optional[float] = None
    ) -> bool:
        """
        WHY: ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð° (Ð²Ñ‹Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ñ‡ÐµÑ€ÐµÐ· 1 Ñ‡Ð°Ñ Ð¿Ð¾ÑÐ»Ðµ ÑÐ¼ÐµÑ€Ñ‚Ð¸).
        
        Args:
            lifecycle_id: UUID ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ
            outcome: 'BREACH' | 'EXHAUSTION' | 'CANCEL'
            price_move_1h_after: ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚Ð½Ð¾Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ñ†ÐµÐ½Ñ‹ Ñ‡ÐµÑ€ÐµÐ· 1Ñ‡
        
        Returns:
            True ÐµÑÐ»Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾
        """
        if not self.pool:
            return False
        
        query = """
            UPDATE iceberg_lifecycle
            SET outcome = $1,
                price_move_1h_after = $2
            WHERE id = $3;
        """
        
        try:
            async with self.pool.acquire() as conn:
                await conn.execute(query, outcome, price_move_1h_after, lifecycle_id)
                return True
        except Exception as e:
            print(f"âŒ Update lifecycle outcome error: {e}")
            return False
    
    async def get_aggregated_smart_candles(
        self,
        symbol: str,
        timeframe: str,
        limit: int = 100
    ) -> List[SmartCandle]:
        """
        WHY: Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ SmartCandles Ð´Ð»Ñ cold start (Ð—ÐÐ”ÐÐ§Ð 3).
        
        SQL-Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ market_metrics_full Ð² SmartCandles.
        Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ HistoricalMemory Ð´Ð»Ñ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸.
        
        Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð°: market_metrics_full (Ð¿Ð¸ÑˆÐµÑ‚ÑÑ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5-10 ÑÐµÐº)
        ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ: date_bin(timeframe) + ÑÑ€ÐµÐ´Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        
        Args:
            symbol: BTCUSDT, ETHUSDT
            timeframe: '1h', '4h', '1d', '1w'
            limit: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ²ÐµÑ‡ÐµÐ¹
        
        Returns:
            List[SmartCandle] Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        """
        if not self.pool:
            return []
        # WHY: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ timeframe Ð² interval
        interval_map = {
            '1h': '1 hour',
            '4h': '4 hours',
            '1d': '1 day',
            '1w': '7 days'
        }
        
        interval = interval_map.get(timeframe)
        if not interval:
            print(f"âš ï¸  Invalid timeframe: {timeframe}")
            return []
        
        # WHY: SQL-Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸ÐµÐ¹ (ÐžÐ‘ÐÐžÐ’Ð›Ð•ÐÐž Ð¿Ð¾Ð´ Migration 005)
        query = f"""
            SELECT 
                date_bin($1::interval, time, '2020-01-01'::timestamptz) AS candle_time,
                $2 AS symbol,
                AVG(price) AS close,  -- WHY: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ close Ð´Ð»Ñ Ñ†ÐµÐ½Ñ‹
                AVG(book_ofi) AS avg_ofi,
                AVG(book_obi) AS avg_obi,
                AVG(spread_bps) AS avg_spread_bps,
                -- WHY: CVD Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÐºÑƒÐ¼ÑƒÐ»ÑÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ (Ð¿Ð¾ÐºÐ° Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð±ÐµÑ€Ñ‘Ð¼ last)
                LAST(flow_whale_cvd_delta, time) AS whale_cvd,
                LAST(flow_minnow_cvd_delta, time) AS minnow_cvd
            FROM market_metrics_full
            WHERE symbol = $2
            GROUP BY candle_time
            ORDER BY candle_time DESC
            LIMIT $3;
        """
        
        try:
            async with self.pool.acquire() as conn:
                rows = await conn.fetch(query, interval, symbol, limit)
                
                # WHY: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð² SmartCandle
                candles = []
                for row in reversed(rows):  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð² Ñ…Ñ€Ð¾Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ
                    candle = SmartCandle(
                        timestamp=row['candle_time'],
                        symbol=row['symbol'],
                        close=Decimal(str(row['close'])),
                        whale_cvd=float(row['whale_cvd']) if row['whale_cvd'] else 0.0,
                        minnow_cvd=float(row['minnow_cvd']) if row['minnow_cvd'] else 0.0,
                        ofi=float(row['avg_ofi']) if row['avg_ofi'] else 0.0,
                        obi=float(row['avg_obi']) if row['avg_obi'] else 0.0
                    )
                    candles.append(candle)
                
                return candles
                
        except Exception as e:
            print(f"âŒ get_aggregated_smart_candles error: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def get_materialized_candles(
        self,
        symbol: str,
        start_time: datetime,
        end_time: datetime,
        timeframe: str = '1h',
        version: str = '1.0'
    ) -> List[SmartCandle]:
        """
        WHY: O(1) SELECT Ð²Ð¼ÐµÑÑ‚Ð¾ O(N) Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸.
        PERFORMANCE: 15 ÑÐµÐº â†’ 0.3 ÑÐµÐº.
        REPRODUCIBILITY: Frozen features Ð´Ð»Ñ ML.
        
        Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ get_aggregated_smart_candles(), ÑÑ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚
        ÐœÐÐ¢Ð•Ð Ð˜ÐÐ›Ð˜Ð—ÐžÐ’ÐÐÐÐ«Ð• ÑÐ²ÐµÑ‡Ð¸ Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ smart_candles.
        
        ÐŸÑ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°:
        1. CONSISTENCY: Ð Ð°Ð· ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½Ð½Ñ‹Ðµ ÑÐ²ÐµÑ‡Ð¸ Ð½Ðµ Ð¼ÐµÐ½ÑÑŽÑ‚ÑÑ
        2. SPEED: ÐŸÑ€ÑÐ¼Ð¾Ð¹ SELECT Ð²Ð¼ÐµÑÑ‚Ð¾ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸ market_metrics_full
        3. VERSIONING: ÐœÐ¾Ð¶Ð½Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð²ÐµÑ€ÑÐ¸Ð¸ Ñ„Ð¾Ñ€Ð¼ÑƒÐ» (v1.0, v2.0)
        4. REPRODUCIBILITY: Backtesting Ð½Ð° Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        
        Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
        - ML training (XGBoost, HMM) - Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ FROZEN features
        - Backtesting - Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ reproducible results
        - HistoricalMemory - Ð´Ð»Ñ cold start Ð°Ð³ÐµÐ½Ñ‚Ð°
        
        Args:
            symbol: BTCUSDT, ETHUSDT, SOLUSDT
            start_time: ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°
            end_time: ÐšÐ¾Ð½ÐµÑ† Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°
            timeframe: '1h', '4h', '1d', '1w'
            version: '1.0' (aggregation formula version)
        
        Returns:
            List[SmartCandle] Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ candle_time
        
        Example:
            >>> repo = PostgresRepository(DB_DSN)
            >>> await repo.connect()
            >>> candles = await repo.get_materialized_candles(
            ...     symbol='BTCUSDT',
            ...     start_time=datetime(2025, 1, 1),
            ...     end_time=datetime(2025, 1, 7),
            ...     timeframe='1h'
            ... )
            >>> len(candles)  # 168 hourly candles (7 days * 24 hours)
        """
        if not self.pool:
            return []
        
        query = """
            SELECT
                symbol, timeframe, candle_time,
                open, high, low, close, volume,
                whale_cvd, minnow_cvd, dolphin_cvd, total_trades,
                avg_basis_apr, min_basis_apr, max_basis_apr,
                options_skew, oi_delta,
                avg_ofi, avg_obi, avg_spread_bps,
                total_gex,
                avg_vpin_score, max_vpin_score,
                wyckoff_pattern, accumulation_confidence
            FROM smart_candles
            WHERE symbol = $1
              AND timeframe = $2
              AND candle_time >= $3
              AND candle_time < $4
              AND aggregation_version = $5
            ORDER BY candle_time ASC;
        """
        
        try:
            async with self.pool.acquire() as conn:
                rows = await conn.fetch(
                    query, symbol, timeframe, start_time, end_time, version
                )
                
                # WHY: ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² SmartCandle objects
                candles = []
                for row in rows:
                    candle = SmartCandle(
                        symbol=row['symbol'],
                        timeframe=row['timeframe'],
                        candle_time=row['candle_time'],
                        
                        # OHLCV
                        open=Decimal(str(row['open'])),
                        high=Decimal(str(row['high'])),
                        low=Decimal(str(row['low'])),
                        close=Decimal(str(row['close'])),
                        volume=Decimal(str(row['volume'])),
                        
                        # CVD
                        whale_cvd=float(row['whale_cvd'] or 0),
                        minnow_cvd=float(row['minnow_cvd'] or 0),
                        total_trades=int(row['total_trades'] or 0),
                        
                        # Derivatives
                        avg_basis_apr=float(row['avg_basis_apr']) if row['avg_basis_apr'] else None,
                        options_skew=float(row['options_skew']) if row['options_skew'] else None,
                        oi_delta=float(row['oi_delta']) if row['oi_delta'] else None,
                        
                        # Microstructure
                        ofi=float(row['avg_ofi'] or 0),
                        weighted_obi=float(row['avg_obi'] or 0),
                        
                        # Gamma
                        total_gex=float(row['total_gex']) if row['total_gex'] else None,
                        
                        # Wyckoff
                        wyckoff_pattern=row['wyckoff_pattern'],
                        accumulation_confidence=float(row['accumulation_confidence']) if row['accumulation_confidence'] else None
                    )
                    candles.append(candle)
                
                return candles
                
        except Exception as e:
            print(f"âŒ get_materialized_candles error: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    # ========================================================================
    # GRIM REAPER: Retrospective Labeling (Step 3)
    # ========================================================================
    
    async def run_grim_reaper_labeling(self, batch_size: int = 100):
        """
        WHY: Ð ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… (Dynamic Labeling).
        Ð—Ð°Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ y_strategic_result, Ð³Ð»ÑÐ´Ñ Ð² Ð±ÑƒÐ´ÑƒÑ‰ÐµÐµ.
        
        ÐŸÑ€Ð¾Ñ†ÐµÑÑ:
        1. ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð½ÐµÑ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ðµ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð¸ ÑÑ‚Ð°Ñ€ÑˆÐµ 7 Ð´Ð½ÐµÐ¹
        2. Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´ (Win/Loss/Neutral)
        3. ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ y_strategic_result Ð² Ð‘Ð”
        
        Args:
            batch_size: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð° Ñ€Ð°Ð·
        
        Returns:
            ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹
        """
        if not self.pool:
            print("âš ï¸ Grim Reaper: Pool not connected")
            return 0
        
        print("ðŸ’€ Grim Reaper: Starting labeling process...")
        
        # 1. ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½ÐµÑ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ðµ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð¸ ÑÑ‚Ð°Ñ€ÑˆÐµ 7 Ð´Ð½ÐµÐ¹ (Ð´Ð»Ñ Strategic Swing)
        # WHY: ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð¿Ð¾Ð´Ñ‚ÑÐ³Ð¸Ð²Ð°ÐµÐ¼ CVD Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Smart Settling!
        fetch_query = """
            SELECT 
                l.id, l.symbol, l.price, l.is_ask, l.event_time, 
                l.volatility_at_entry, l.vpin_at_entry, l.t_settled,
                
                -- WHY: ÐŸÐ¾Ð´Ñ‚ÑÐ³Ð¸Ð²Ð°ÐµÐ¼ CVD Ð´ÐµÐ»ÑŒÑ‚Ñ‹ Ð¸Ð· feature_snapshot
                -- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ COALESCE ÐµÑÐ»Ð¸ snapshot Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚
                COALESCE(f.whale_cvd_delta_5m, 0) as whale_cvd_delta,
                COALESCE((
                    SELECT SUM(flow_minnow_cvd_delta) 
                    FROM market_metrics_full 
                    WHERE symbol = l.symbol 
                      AND time BETWEEN l.event_time - INTERVAL '5 minutes' AND l.event_time
                ), 0) as minnow_cvd_delta,
                
                -- === GEMINI FIX #1: Algo Detection (Stealth Whale Protection) ===
                -- WHY: ÐŸÐ¾Ð´Ñ‚ÑÐ³Ð¸Ð²Ð°ÐµÐ¼ spoofing_score ÐºÐ°Ðº proxy Ð´Ð»Ñ algo detection
                -- Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ spoofing_score = Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸ (TWAP/VWAP/Iceberg)
                COALESCE(f.spoofing_score, 0) as algo_score
                
            FROM iceberg_lifecycle l
            LEFT JOIN iceberg_feature_snapshot f 
              ON f.lifecycle_event_id = l.id
            WHERE l.y_strategic_result IS NULL
              AND l.event_time < NOW() - INTERVAL '7 days'
            LIMIT $1;
        """
        
        labeled_count = 0
        
        try:
            async with self.pool.acquire() as conn:
                candidates = await conn.fetch(fetch_query, batch_size)
                print(f"ðŸ’€ Grim Reaper: Found {len(candidates)} candidates for labeling.")
                
                for row in candidates:
                    # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¸ÑÑ…Ð¾Ð´
                    outcome = await self._calculate_outcome(conn, row)
                    
                    # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
                    await conn.execute("""
                        UPDATE iceberg_lifecycle
                        SET y_strategic_result = $1
                        WHERE id = $2
                    """, outcome, row['id'])
                    
                    labeled_count += 1
                
                print(f"ðŸ’€ Grim Reaper: Labeled {labeled_count} icebergs.")
                return labeled_count
                
        except Exception as e:
            print(f"âŒ Grim Reaper error: {e}")
            import traceback
            traceback.print_exc()
            return labeled_count
    
    # =========================================================================
    # ML DATASET PREPARATION (with Data Leakage Protection)
    # =========================================================================
    async def prepare_ml_dataset_safe(
        self,
        start_date: datetime,
        end_date: datetime,
        timeframe: str = '1h',
        target_col: str = 'next_hour_close',
        symbol: str = 'BTCUSDT'
    ) -> pd.DataFrame:
        """
        ðŸ›¡ï¸ Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐÐ¯ ÐŸÐžÐ”Ð“ÐžÐ¢ÐžÐ’ÐšÐ Ð”ÐÐ¢ÐÐ¡Ð•Ð¢Ð Ð”Ð›Ð¯ ML
        
        WHY: ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ SmartCandles + IcebergFeatures Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹.
        Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÐÐ• Ð’Ð˜Ð”Ð˜Ð¢ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð±ÑƒÐ´ÑƒÑ‰ÐµÐ³Ð¾ (Data Leakage Protection).
        
        Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚:
        1. pd.merge_asof(..., direction='backward') - Ð±ÐµÑ€ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ðµ
        2. DataLeakageGuard - 5 Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¾Ðº Ð½Ð° ÑƒÑ‚ÐµÑ‡ÐºÐ¸
        3. Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ timeframe Ð¸ aggregation_version
        
        Args:
            start_date: ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
            end_date: ÐšÐ¾Ð½ÐµÑ† Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
            timeframe: Ð¢Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼ ÑÐ²ÐµÑ‡ÐµÐ¹ ('1h', '4h', '1d', '1w', '1m')
            target_col: Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
            symbol: Ð¢Ð¾Ñ€Ð³Ð¾Ð²Ð°Ñ Ð¿Ð°Ñ€Ð° (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ BTCUSDT)
        
        Returns:
            pd.DataFrame: ÐŸÑ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚, Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ Ð´Ð»Ñ model.fit()
            
        Raises:
            ValueError: Ð•ÑÐ»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° ÑƒÑ‚ÐµÑ‡ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… (timestamp/correlation/shift)
        
        Example:
            repo = PostgresRepository(dsn="postgresql://...")
            await repo.connect()
            
            # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð·Ð°Ñ‰Ð¸Ñ‚Ð¾Ð¹
            df = await repo.prepare_ml_dataset_safe(
                start_date=datetime(2024, 1, 1),
                end_date=datetime(2024, 12, 1),
                timeframe='1h',
                target_col='next_hour_close'
            )
            
            # Ð•ÑÐ»Ð¸ ÐºÐ¾Ð´ Ð´Ð¾ÑˆÐµÐ» ÑÑŽÐ´Ð° - Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ‡Ð¸ÑÑ‚Ñ‹!
            from xgboost import XGBRegressor
            X = df.drop(columns=['candle_time', 'next_hour_close', 'snapshot_time'])
            y = df['next_hour_close']
            model = XGBRegressor()
            model.fit(X, y)  # âœ… ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… ÑƒÑ‚ÐµÑ‡ÐµÐº!
        """
        async with self.pool.acquire() as conn:
            # 1. Ð—ÐÐ“Ð Ð£Ð—ÐšÐ SMARTCANDLES (Ñ‚Ð°Ñ€Ð³ÐµÑ‚)
            print(f"ðŸ” Loading SmartCandles ({timeframe}) from {start_date} to {end_date}...")
            candles_raw = await conn.fetch("""
                SELECT 
                    candle_time,
                    symbol,
                    timeframe,
                    aggregation_version,
                    open,
                    high,
                    low,
                    close,
                    volume,
                    
                    -- ÐœÐ¸ÐºÑ€Ð¾ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°
                    avg_ofi,
                    avg_obi,
                    
                    -- CVD ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹
                    whale_cvd_change,
                    dolphin_cvd_change,
                    minnow_cvd_change,
                    
                    -- Ð”ÐµÑ€Ð¸Ð²Ð°Ñ‚Ð¸Ð²Ñ‹
                    avg_basis_apr,
                    avg_options_skew,
                    
                    -- Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ (ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð°Ñ ÑÐ²ÐµÑ‡Ð°)
                    LEAD(close) OVER (ORDER BY candle_time) as next_hour_close
                    
                FROM smart_candles
                WHERE candle_time >= $1
                  AND candle_time <= $2
                  AND timeframe = $3
                  AND symbol = $4
                  AND aggregation_version = '1.0'
                ORDER BY candle_time
            """, start_date, end_date, timeframe, symbol)
            
            if not candles_raw:
                raise ValueError(f"No SmartCandles found for {symbol} {timeframe} in date range")
            
            candles = pd.DataFrame(candles_raw)
            print(f"   âœ… Loaded {len(candles)} candles")
            
            # 2. Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ICEBERG FEATURES (Ð¿Ñ€ÐµÐ´Ð¸ÐºÑ‚Ð¾Ñ€Ñ‹)
            print(f"ðŸ” Loading IcebergFeatures from {start_date} to {end_date}...")
            features_raw = await conn.fetch("""
                SELECT 
                    snapshot_time,
                    lifecycle_event_id,
                    
                    -- Orderbook
                    obi_value,
                    ofi_value,
                    spread_bps,
                    depth_ratio,
                    
                    -- CVD Flow
                    whale_cvd,
                    dolphin_cvd,
                    whale_cvd_delta_5m,
                    total_cvd,
                    
                    -- Derivatives
                    futures_basis_apr,
                    basis_state,
                    options_skew,
                    skew_state,
                    total_gex,
                    dist_to_gamma_wall,
                    gamma_wall_type,
                    
                    -- Price
                    current_price,
                    twap_5m,
                    price_vs_twap_pct,
                    volatility_1h,
                    
                    -- Anti-Spoofing
                    spoofing_score,
                    cancel_ratio_5m,
                    
                    -- Regime
                    trend_regime,
                    volatility_regime,
                    
                    -- Smart Money Context (Deep Memory)
                    whale_cvd_trend_1w,
                    whale_cvd_trend_1m,
                    whale_cvd_trend_3m,
                    whale_cvd_trend_6m
                    
                FROM iceberg_feature_snapshot
                WHERE snapshot_time >= $1
                  AND snapshot_time <= $2
                ORDER BY snapshot_time
            """, start_date, end_date)
            
            if not features_raw:
                print("   âš ï¸  No IcebergFeatures found (may train on SmartCandles only)")
                features = pd.DataFrame()
            else:
                features = pd.DataFrame(features_raw)
                print(f"   âœ… Loaded {len(features)} feature snapshots")
            
            # 3. Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐ«Ð™ MERGE (backward only)
            print(f"ðŸ”— Merging candles + features (safe merge_asof)...")
            
            if features.empty:
                # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ñ„Ð¸Ñ‡ÐµÐ¹ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ²ÐµÑ‡Ð¸
                df = candles.copy()
                print("   âš ï¸  Training on SmartCandles only (no iceberg features)")
            else:
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ safe_merge_candles_features (backward merge)
                df = safe_merge_candles_features(
                    candles,
                    features,
                    candle_time_col='candle_time',
                    feature_time_col='snapshot_time'
                )
            
            # 4. ðŸ›¡ï¸ Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð¯ Ð”ÐÐÐÐ«Ð¥ (Data Leakage Guard)
            print(f"ðŸ›¡ï¸ Running Data Leakage Guard...")
            
            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ (Ñƒ Ð½ÐµÐµ Ð½ÐµÑ‚ next_hour_close Ð¸Ð·-Ð·Ð° LEAD)
            df = df[df[target_col].notna()].reset_index(drop=True)
            
            if df.empty:
                raise ValueError("Dataset is empty after removing NaN targets")
            
            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ð»Ð½ÑƒÑŽ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ
            guard = DataLeakageGuard(df, time_col='candle_time', target_col=target_col)
            
            if not features.empty:
                # ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ„Ð¸Ñ‡Ð¸)
                guard.check_all(
                    feature_time_col='snapshot_time',
                    timeframe_col='timeframe',
                    version_col='aggregation_version'
                )
            else:
                # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ²ÐµÑ‡Ð¸)
                guard.check_timeframe_consistency('timeframe')
                guard.check_aggregation_version('aggregation_version')
            
            print(f"âœ… Dataset validated: {len(df)} rows, {len(df.columns)} columns")
            print(f"âœ… Safe for ML training (no data leakage detected)")
            
            return df
    
    async def _calculate_outcome(self, conn, iceberg) -> int:
        """
        WHY: Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´ ÑÐ´ÐµÐ»ÐºÐ¸ Ð½Ð° Ð³Ð¾Ñ€Ð¸Ð·Ð¾Ð½Ñ‚Ðµ 7 Ð´Ð½ÐµÐ¹.
        
        === UPDATE: Settling Time Support (Gemini Recommendation) ===
        Ð¢ÐµÐ¿ÐµÑ€ÑŒ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ VPIN Ð¸ Ð¾Ñ‚ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐµÑÐ»Ð¸ Ñ€Ñ‹Ð½Ð¾Ðº "Ð³Ð¾Ñ€ÑÑ‡Ð¸Ð¹".
        
        Ð›Ð¾Ð³Ð¸ÐºÐ° Ð±Ð°Ñ€ÑŒÐµÑ€Ð¾Ð²:
        - BUY Iceberg (is_ask=False): Win ÐµÑÐ»Ð¸ Ñ†ÐµÐ½Ð° Ñ€Ð°ÑÑ‚Ñ‘Ñ‚ Ð²Ñ‹ÑˆÐµ take_profit
        - SELL Iceberg (is_ask=True): Win ÐµÑÐ»Ð¸ Ñ†ÐµÐ½Ð° Ð¿Ð°Ð´Ð°ÐµÑ‚ Ð½Ð¸Ð¶Ðµ take_profit
        
        Ð‘Ð°Ñ€ÑŒÐµÑ€Ñ‹:
        - stop_loss: entry Â± 3 * ATR (ÑˆÐ¸Ñ€Ð¾ÐºÐ¸Ðµ ÑÑ‚Ð¾Ð¿Ñ‹ Ð´Ð»Ñ ÑÐ²Ð¸Ð½Ð³Ð°)
        - take_profit: entry Â± 6 * ATR (R:R = 1:2)
        
        Settling Time Logic:
        - Ð•ÑÐ»Ð¸ VPIN > 0.7 (Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ) â†’ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 15-30 Ð¼Ð¸Ð½
        - Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ "Ð¾ÑÑ‚Ñ‹Ñ‚ÑŒ" Ñ€Ñ‹Ð½ÐºÑƒ Ð¿Ñ€ÐµÐ¶Ð´Ðµ Ñ‡ÐµÐ¼ Ð¾Ñ†ÐµÐ½Ð¸Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        - Ð˜ÑÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ ÐºÑ€Ð°Ñ‚ÐºÐ¾ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ð¹ ÑˆÑƒÐ¼ ÑÑ€Ð°Ð·Ñƒ Ð¿Ð¾ÑÐ»Ðµ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸
        
        Args:
            conn: Database connection
            iceberg: Row Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð°Ð¹ÑÐ±ÐµÑ€Ð³Ð°
        
        Returns:
            1 = Win, 0 = Neutral, -1 = Loss
        """
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ATR (volatility_at_entry)
        atr = float(iceberg['volatility_at_entry'] or 0)
        
        if atr == 0:
            return 0  # WHY: ÐÐµ Ð¼Ð¾Ð¶ÐµÐ¼ Ð¿Ð¾ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð±ÐµÐ· ATR
        
        price = float(iceberg['price'])
        is_ask = iceberg['is_ask']
        
        # WHY: Wide Stops Ð´Ð»Ñ Swing Trading (3x ATR)
        stop_dist = 3.0 * atr
        take_dist = 6.0 * atr  # Risk/Reward 1:2
        
        # WHY: Ð‘Ð°Ñ€ÑŒÐµÑ€Ñ‹ Ð·Ð°Ð²Ð¸ÑÑÑ‚ Ð¾Ñ‚ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
        if is_ask:  # SELL Iceberg (ÑÐ¾Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð»ÐµÐ½Ð¸Ðµ)
            upper_barrier = price + stop_dist   # Stop Loss Ð²Ñ‹ÑˆÐµ
            lower_barrier = price - take_dist   # Take Profit Ð½Ð¸Ð¶Ðµ
        else:  # BUY Iceberg (Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°)
            upper_barrier = price + take_dist   # Take Profit Ð²Ñ‹ÑˆÐµ
            lower_barrier = price - stop_dist   # Stop Loss Ð½Ð¸Ð¶Ðµ
        
        # === GEMINI FIX #2: Falling Knife Veto (Cascade Protection) ===
        # WHY: ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐºÑÑ‚Ñ€ÐµÐ¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (ÐºÐ°ÑÐºÐ°Ð´ Ð»Ð¸ÐºÐ²Ð¸Ð´Ð°Ñ†Ð¸Ð¹)
        # Ð•ÑÐ»Ð¸ ATR > 2% Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‹ -> VETO Ð½Ð° Ð²Ñ…Ð¾Ð´ Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ Ð¾Ñ‚ Ð¿Ð°Ð½Ð¸ÐºÐ¸
        # Ð­Ñ‚Ð¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº "falling knife" - Ñ†ÐµÐ½Ð° Ð¿Ñ€Ð¾Ð»ÐµÑ‚Ð¸Ñ‚ Ñ‡ÐµÑ€ÐµÐ· Ð°Ð¹ÑÐ±ÐµÑ€Ð³
        atr_pct = (atr / price) * 100  # ATR Ð² % Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‹
        event_time = iceberg['event_time']
        
        # HARD VETO: Ð•ÑÐ»Ð¸ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ >2% -> Ð·Ð°Ð¿Ñ€ÐµÑ‚ Ð²Ñ…Ð¾Ð´Ð°
        if atr_pct > 2.0:
            # WHY: Ð­ÐºÑÑ‚Ñ€ÐµÐ¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ = ÐºÐ°ÑÐºÐ°Ð´ Ð»Ð¸ÐºÐ²Ð¸Ð´Ð°Ñ†Ð¸Ð¹
            # Ð¦ÐµÐ½Ð° Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ñ€Ð¾Ð»ÐµÑ‚ÐµÑ‚ÑŒ Ð½Ð° 5-10% Ð·Ð° Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ
            # ÐÐ¹ÑÐ±ÐµÑ€Ð³ Ð±ÑƒÐ´ÐµÑ‚ ÑÐ½ÐµÑÐµÐ½ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ market orders
            # Ð–Ð”Ð•Ðœ Ð·Ð°Ñ‚ÑƒÑ…Ð°Ð½Ð¸Ñ Ð¸Ð¼Ð¿ÑƒÐ»ÑŒÑÐ° (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 30 Ð¼Ð¸Ð½)
            start_time = event_time + timedelta(minutes=30)
            # Optional: Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
            # print(f"ðŸ”¥ FALLING KNIFE! ATR={atr_pct:.2f}%. Forced 30min settling.")
            
        # Ð•ÑÐ»Ð¸ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ -> Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Smart Settling
        elif iceberg.get('t_settled'):
            # WHY: Ð•ÑÐ»Ð¸ t_settled ÑƒÐ¶Ðµ Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ð½ Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ³Ð¾
            start_time = iceberg['t_settled']
        
        # === GEMINI FIX: Smart Settling Time (CRYPTO-AWARE) ===
        # WHY: Ð Ð°Ð·Ð»Ð¸Ñ‡Ð°ÐµÐ¼ Panic Absorption (Ð²Ñ…Ð¾Ð´ ÑÑ€Ð°Ð·Ñƒ) vs Whale Attack (Ð¶Ð´ÐµÐ¼)
        else:
            vpin = float(iceberg.get('vpin_at_entry') or 0)
            
            if vpin > 0.7:
                # WHY: High VPIN â†’ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð˜Ð¡Ð¢ÐžÐ§ÐÐ˜Ðš Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
                
                # 1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÑ‚Ð¾ ÑÐ¾Ð·Ð´Ð°Ð» VPIN (ÐºÐ¸Ñ‚Ñ‹ Ð¸Ð»Ð¸ Ñ€Ñ‹Ð±Ñ‹)
                minnow_cvd_delta = float(iceberg.get('minnow_cvd_delta') or 0)
                whale_cvd_delta = float(iceberg.get('whale_cvd_delta') or 0)
                
                # 2. Panic Absorption: Minnows Ð¿Ð°Ð½Ð¸ÐºÑƒÑŽÑ‚ (CVD Ð¿Ð°Ð´Ð°ÐµÑ‚), Whales Ð¿Ð¾ÐºÑƒÐ¿Ð°ÑŽÑ‚
                is_panic_dump = (minnow_cvd_delta < whale_cvd_delta)
                
                # === GEMINI FIX #1: Algo Detection (Stealth Whale Protection) ===
                # WHY: ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸
                # Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ algo_score Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚ TWAP/VWAP/Iceberg Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼
                # Ð­Ñ‚Ð¾ ÐÐ• Ð¿Ð°Ð½Ð¸ÐºÐ° - ÑÑ‚Ð¾ ÑÑ‚ÐµÐ»Ñ-ÐºÐ¸Ñ‚, Ð¼Ð°ÑÐºÐ¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ÑÑ Ð¿Ð¾Ð´ Ñ€Ñ‹Ð±Ñƒ!
                algo_score = float(iceberg.get('algo_score', 0))
                is_algo_selling = (algo_score > 0.7)
                
                # CRITICAL: Ð¢ÐžÐ›Ð¬ÐšÐž Ñ…Ð°Ð¾Ñ‚Ð¸Ñ‡Ð½Ð°Ñ Ð¿Ð°Ð½Ð¸ÐºÐ° = Panic Absorption
                # Ð•ÑÐ»Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ -> Ð­Ð¢Ðž ÐšÐ˜Ð¢, Ð¶Ð´ÐµÐ¼!
                if is_panic_dump and not is_algo_selling:
                    # Ð¡Ð¦Ð•ÐÐÐ Ð˜Ð™ Ð: TRUE Panic Absorption (V-shape recovery)
                    # WHY: ÐÐ• Ð–Ð”Ð•Ðœ! Ð’Ñ…Ð¾Ð´Ð¸Ð¼ ÑÑ€Ð°Ð·Ñƒ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð¹Ð¼Ð°Ñ‚ÑŒ Ð¾Ñ‚ÑÐºÐ¾Ðº
                    # Ð­Ñ‚Ð¾ ÑÐ°Ð¼Ñ‹Ðµ Ð¿Ñ€Ð¸Ð±Ñ‹Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ´ÐµÐ»ÐºÐ¸ Ð² ÐºÑ€Ð¸Ð¿Ñ‚Ðµ
                    start_time = event_time
                    # Optional: Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
                    # print(f"âš¡ TRUE Panic Absorption (VPIN={vpin:.2f}, algo={algo_score:.2f}). No delay.")
                else:
                    # Ð¡Ð¦Ð•ÐÐÐ Ð˜Ð™ Ð‘: Whale Attack / Algo Masking / ÐÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ
                    # WHY: Ð–Ð”Ð•Ðœ Ð¾ÑÑ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ Ñ€Ñ‹Ð½ÐºÐ° (15-30 Ð¼Ð¸Ð½)
                    settling_minutes = 15 + int((vpin - 0.7) * 50)
                    start_time = event_time + timedelta(minutes=settling_minutes)
                    # Optional: Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
                    # if is_algo_selling:
                    #     print(f"ðŸ¤– Algo Detected ({algo_score:.2f}). Settling {settling_minutes}m.")
                    # else:
                    #     print(f"âš ï¸ High VPIN risk ({vpin:.2f}). Settling {settling_minutes}m.")
            else:
                # WHY: Low VPIN â†’ ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ñ‹Ð¹ Ñ€Ñ‹Ð½Ð¾Ðº â†’ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ ÑÑ€Ð°Ð·Ñƒ
                start_time = event_time
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÐ²ÐµÑ‡Ð¸ ÐŸÐžÐ¡Ð›Ð• settling period (ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ 7 Ð´Ð½ÐµÐ¹)
        try:
            candles = await conn.fetch("""
                SELECT price as close, time 
                FROM market_metrics_full
                WHERE symbol = $1 
                  AND time > $2 
                  AND time < $3
                ORDER BY time ASC
            """, iceberg['symbol'], start_time, start_time + timedelta(days=7))
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ ÑÐ²ÐµÑ‡Ñƒ Ð½Ð° Ð¿Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸Ðµ Ð±Ð°Ñ€ÑŒÐµÑ€Ð¾Ð²
            # WHY: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ²ÐµÑ‡Ð¸ ÐŸÐžÐ¡Ð›Ð• start_time (ÑƒÐ¶Ðµ Ð¾Ñ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ñ‹ SQL)
            for c in candles:
                p = float(c['close'])
                
                if is_ask:  # SELL Iceberg
                    if p >= upper_barrier:
                        return -1  # Loss (Stop Hit)
                    if p <= lower_barrier:
                        return 1   # Win (Take Hit)
                else:  # BUY Iceberg
                    if p <= lower_barrier:
                        return -1  # Loss (Stop Hit)
                    if p >= upper_barrier:
                        return 1   # Win (Take Hit)
            
            # WHY: Time Expiration - Ð½Ð¸ Ð¾Ð´Ð¸Ð½ Ð±Ð°Ñ€ÑŒÐµÑ€ Ð½Ðµ Ð¿Ñ€Ð¾Ð±Ð¸Ñ‚ Ð·Ð° 7 Ð´Ð½ÐµÐ¹
            return 0
            
        except Exception as e:
            print(f"âš ï¸ _calculate_outcome error for iceberg {iceberg['id']}: {e}")
            return 0  # WHY: ÐŸÑ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Neutral